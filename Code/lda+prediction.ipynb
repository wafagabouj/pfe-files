{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd().replace('/Code', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from sklearn import decomposition, preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, spacy\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "## Setup nlp for spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load NLTK stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# Add some extra words in it if required\n",
    "stop_words.extend(['from', 'subject', 'use','pron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8083, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('Matrices/CVs_SW_old.pkl.gz', 'rb') as f:\n",
    "        CVs = pkl.load(f)\n",
    "CVs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA ANALYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words=CVs[\"vocab_cv_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_words.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_clean = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(data_words_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in data_words_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel.load('LDA_NYTBIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.028*\"sql\" + 0.028*\"server\" + 0.018*\"environment\" + 0.017*\"production\" + 0.017*\"database\" + 0.015*\"unix\" + 0.013*\"administration\" + 0.012*\"support\" + 0.010*\"shell\" + 0.009*\"dba\"'),\n",
       " (1,\n",
       "  '0.016*\"manager\" + 0.013*\"customer\" + 0.009*\"digital\" + 0.008*\"support\" + 0.008*\"marketing\" + 0.008*\"service\" + 0.007*\"sale\" + 0.007*\"production\" + 0.007*\"communication\" + 0.007*\"video\"'),\n",
       " (2,\n",
       "  '0.022*\"server\" + 0.021*\"windows\" + 0.021*\"network\" + 0.014*\"security\" + 0.012*\"infrastructure\" + 0.011*\"deployment\" + 0.011*\"administration\" + 0.010*\"cisco\" + 0.010*\"engineer\" + 0.009*\"environment\"'),\n",
       " (3,\n",
       "  '0.019*\"functional\" + 0.012*\"monitoring\" + 0.011*\"manager\" + 0.010*\"specification\" + 0.010*\"test\" + 0.008*\"tool\" + 0.008*\"support\" + 0.007*\"user\" + 0.007*\"accounting\" + 0.007*\"plan\"'),\n",
       " (4,\n",
       "  '0.012*\"risk\" + 0.011*\"market\" + 0.011*\"financial\" + 0.011*\"office\" + 0.009*\"analyst\" + 0.008*\"finance\" + 0.007*\"support\" + 0.007*\"customer\" + 0.007*\"product\" + 0.007*\"bank\"'),\n",
       " (5,\n",
       "  '0.038*\"java\" + 0.014*\"j2ee\" + 0.013*\"design\" + 0.012*\"spring\" + 0.012*\"environment\" + 0.011*\"eclipse\" + 0.010*\"web\" + 0.010*\"engineer\" + 0.009*\"service\" + 0.009*\"test\"'),\n",
       " (6,\n",
       "  '0.027*\"sql\" + 0.023*\"net\" + 0.020*\"c\" + 0.017*\"test\" + 0.014*\"server\" + 0.011*\"environment\" + 0.011*\"design\" + 0.011*\"visual\" + 0.010*\"asp\" + 0.010*\"software\"'),\n",
       " (7,\n",
       "  '0.027*\"web\" + 0.024*\"developer\" + 0.014*\"php\" + 0.013*\"javascript\" + 0.011*\"design\" + 0.010*\"mysql\" + 0.010*\"jquery\" + 0.009*\"html\" + 0.008*\"technology\" + 0.007*\"js\"'),\n",
       " (8,\n",
       "  '0.027*\"data\" + 0.016*\"datum\" + 0.010*\"big\" + 0.009*\"r\" + 0.008*\"python\" + 0.008*\"science\" + 0.008*\"university\" + 0.007*\"design\" + 0.006*\"computer\" + 0.006*\"engineer\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_topic(num):\n",
    "    if num==0:\n",
    "        label=\"DBA \"\n",
    "    elif num==1:\n",
    "        label=\"Media\"\n",
    "    elif num==2:\n",
    "        label=\"Sys ops\"\n",
    "    elif num==3:\n",
    "        label=\"MOA\"\n",
    "    elif num==4:\n",
    "        label=\"Analyste risque\"\n",
    "    elif num==5:\n",
    "        label=\"dev Back-End\"\n",
    "    elif num==6:\n",
    "        label=\"dev Full Stack\"\n",
    "    elif num==7:\n",
    "        label=\"dev Front-End\"\n",
    "    elif num==8:\n",
    "        label=\"Data Ing\"\n",
    "    return label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import langdetect\n",
    "from textblob import TextBlob\n",
    "from multiprocessing import Pool\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_cv(text):\n",
    "        try :\n",
    "            blob = TextBlob(text )\n",
    "            return str(blob.translate(from_lang='fr', to='en'))\n",
    "        except:\n",
    "            return text\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verif_egalite(tab):   \n",
    "    eg=False\n",
    "    for i in range(len(tab)-1):\n",
    "        if tab['prob'][i]==tab['prob'][i+1]:\n",
    "            eg=True\n",
    "    return eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_doc(text):\n",
    "    global translate_cv\n",
    "    global label_topic\n",
    "    global verif_egalite\n",
    "    \n",
    "    data=translate_cv(text)\n",
    "    # Remove single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "\n",
    "    ### Lemmatization\n",
    "    data_lemma = []\n",
    "    lis = []\n",
    "    doc = nlp(data)\n",
    "    for token in doc:\n",
    "        lis.append(token.lemma_)\n",
    "    data_lemma.append(' '.join(lis))\n",
    "\n",
    "    ### Tokenization and gensim stopword removal\n",
    "\n",
    "    # You can look for all gensim stopwords by running -> 'gensim.parsing.preprocessing.STOPWORDS'\n",
    "\n",
    "    # Function to tokenize\n",
    "    # Also remove words whose length less than 3 (you can chang it)\n",
    "    def tokenization_with_gen_stop(text):\n",
    "        result=[]\n",
    "        for token in gensim.utils.simple_preprocess(text) :\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "                result.append(token)\n",
    "\n",
    "        return result\n",
    "\n",
    "    ## Apply tokenization function\n",
    "    data_words = []\n",
    "    for txt in tqdm(data_lemma):\n",
    "        data_words.append(tokenization_with_gen_stop(txt))\n",
    "\n",
    "    ### NLTK Stopword removal (extra stopwords)\n",
    "\n",
    "    data_words_clean_new = []\n",
    "    for word in tqdm(data_words):\n",
    "        for w in word:\n",
    "            if w not in stop_words:\n",
    "                data_words_clean_new.append(w)\n",
    "    ##############################################################################################\n",
    "    corpus_new = dictionary.doc2bow(data_words_clean_new)\n",
    "    liste=ldamodel.get_document_topics(corpus_new)\n",
    "    #table probas\n",
    "    tab=pd.DataFrame(liste)\n",
    "    tab.columns=['topic','prob']\n",
    "    \n",
    "    \n",
    "    if verif_egalite(tab)==False:\n",
    "        #num topic\n",
    "        df=tab.loc[tab['prob']==max(tab['prob'])]\n",
    "        num=df.iloc[0]['topic']\n",
    "        #keys\n",
    "        topic_prob = ldamodel.get_topic_terms(topicid=int(num))\n",
    "        topic_doc=[]\n",
    "        for topic in topic_prob:\n",
    "            topic_doc.append(dictionary[topic[0]])\n",
    "        #nom topic\n",
    "        nom_topic=label_topic(num)\n",
    "    else:\n",
    "        tab=pd.DataFrame()\n",
    "        topic_doc=[]\n",
    "        num=\"\"\n",
    "        nom_topic=\"ce CV ne correspond à aucun topic\"\n",
    "    \n",
    "        \n",
    "    \n",
    "    return tab,topic_doc,num,nom_topic\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"big data r hadoop spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1150.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 733.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tab,topic_doc,num,nom_topic=predict_doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "Data Ing\n",
      "['data', 'datum', 'big', 'r', 'python', 'science', 'university', 'design', 'computer', 'engineer']\n",
      "   topic      prob\n",
      "0      0  0.022224\n",
      "1      1  0.022223\n",
      "2      2  0.022223\n",
      "3      3  0.022223\n",
      "4      4  0.022223\n",
      "5      5  0.022223\n",
      "6      6  0.022223\n",
      "7      7  0.022223\n",
      "8      8  0.822217\n"
     ]
    }
   ],
   "source": [
    "print(num)\n",
    "print(nom_topic)\n",
    "print(topic_doc)\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
